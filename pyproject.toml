[project]
name = "sdpo-rl"
version = "0.1.0"
description = "Self-Distilled Policy Optimization (SDPO) for TRL â€” faithful reimplementation of arxiv:2601.20802"
license = {text = "Apache-2.0"}
readme = "README.md"
requires-python = ">=3.10"
authors = [{name = "SDPO Community"}]

dependencies = [
    "torch>=2.0.0",
    "transformers>=4.50.0",
    "trl>=0.17.0",
    "accelerate>=1.0.0",
    "pytest>=9.0.2",
    "pytest-cov>=7.0.0",
    "datasets>=4.3.0",
    "matplotlib>=3.10.8",
    "setuptools>=80.10.2",
]

[project.optional-dependencies]
unsloth = ["unsloth"]
test = ["pytest", "pytest-cov"]
dev = ["pytest", "pytest-cov", "ruff"]

[project.urls]
Homepage = "https://github.com/sdpo-community/sdpo-trainer"
Paper = "https://arxiv.org/abs/2601.20802"
Reference = "https://github.com/lasgroup/SDPO"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/sdpo_trainer"]

[tool.ruff]
line-length = 120

[tool.ruff.lint]
select = ["E", "F", "UP", "B", "I"]
ignore = ["E501"]

[tool.pytest.ini_options]
testpaths = ["tests"]
addopts = "-v --tb=short"
markers = [
    "gpu: tests that require CUDA GPU (deselect with '-m \"not gpu\"')",
]
